{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Answering - LSTM_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Training AI/NLP Tutorial/Question Answering'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFBXyfER6xPv",
        "outputId": "13b6e1db-3aa6-40ab-a0b8-53bbe4ec918d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Training AI/NLP Tutorial/Question Answering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "ka_VTsYBqAhU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q3uk7fFZZ4CE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate\n",
        "from tensorflow.keras.layers import AdditiveAttention"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Open dataset\n"
      ],
      "metadata": {
        "id": "iRC6utGNqLX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "line_path = \"/content/drive/MyDrive/Training AI/NLP Tutorial/Question Answering/datasets/archive/cornell movie-dialogs corpus/movie_lines.txt\"\n",
        "conver_path = \"/content/drive/MyDrive/Training AI/NLP Tutorial/Question Answering/datasets/archive/cornell movie-dialogs corpus/movie_conversations.txt\""
      ],
      "metadata": {
        "id": "CIRqGGg1hFVg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = open(line_path, encoding='utf-8',\n",
        "             errors='ignore').read().split('\\n')\n",
        "\n",
        "convers = open(conver_path, encoding='utf-8',\n",
        "             errors='ignore').read().split('\\n')"
      ],
      "metadata": {
        "id": "LNnik2tHhCNu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv3s-aJei1e2",
        "outputId": "506b62bc-c2f4-48d6-89ea-67f9bb1424e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!',\n",
              " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!',\n",
              " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.',\n",
              " 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?',\n",
              " \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\",\n",
              " 'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow',\n",
              " \"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\",\n",
              " 'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No',\n",
              " 'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?',\n",
              " 'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lines))\n",
        "print(len(convers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-UDO8SihhO2",
        "outputId": "23cde605-daef-422c-d03a-e7ed4dceea72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304714\n",
            "83098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "t2f--95flimY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convers[0].split(' +++$+++ ')[-1][1:-1].replace(\"'\", '').replace(\",\",\"\").split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IInVy29YjEO2",
        "outputId": "fe6f1da7-c189-4a48-cc1a-65378b7b3411"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['L194', 'L195', 'L196', 'L197']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines[0].split(' +++$+++ ')[-1].replace(\"'\", '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cESzEbzZikxt",
        "outputId": "c75d2e19-b22b-49e6-97cc-3d8b1f135f68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'They do not!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exchn = []\n",
        "for conver in convers:\n",
        "    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n"
      ],
      "metadata": {
        "id": "pDPS9I63ihSn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exchn[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2n3LWsxjjGt",
        "outputId": "b0502f64-b2f2-4bd2-d844-c00a5baa9ea3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['L194', 'L195', 'L196', 'L197'],\n",
              " ['L198', 'L199'],\n",
              " ['L200', 'L201', 'L202', 'L203'],\n",
              " ['L204', 'L205', 'L206'],\n",
              " ['L207', 'L208'],\n",
              " ['L271', 'L272', 'L273', 'L274', 'L275'],\n",
              " ['L276', 'L277'],\n",
              " ['L280', 'L281'],\n",
              " ['L363', 'L364'],\n",
              " ['L365', 'L366']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diag = {}\n",
        "for line in lines:\n",
        "    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]"
      ],
      "metadata": {
        "id": "rgSr1j5NjiPO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict(list(diag.items())[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y87MfgKCj5jF",
        "outputId": "21a6b9a1-c074-4be3-f3ea-6dc632d8d1d6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'L1044': 'They do to!',\n",
              " 'L1045': 'They do not!',\n",
              " 'L869': 'Like my fear of wearing pastels?',\n",
              " 'L870': 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?',\n",
              " 'L871': 'No',\n",
              " 'L872': \"Okay -- you're gonna need to learn how to lie.\",\n",
              " 'L924': 'Wow',\n",
              " 'L925': \"Let's go.\",\n",
              " 'L984': 'She okay?',\n",
              " 'L985': 'I hope so.'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(lines, convers, conver, line)"
      ],
      "metadata": {
        "id": "Su1FFQ71yrQY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for conver in exchn:\n",
        "    for i in range(len(conver) - 1):\n",
        "        questions.append(diag[conver[i]])\n",
        "        answers.append(diag[conver[i+1]])"
      ],
      "metadata": {
        "id": "qu5yA8kDj9UN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_seq = 13"
      ],
      "metadata": {
        "id": "PdVRmBYlvDDo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(diag, exchn, conver, i)"
      ],
      "metadata": {
        "id": "7JmfCO_hyxgP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_ques = []\n",
        "sorted_ans = []\n",
        "for i in range(len(questions)):\n",
        "    if len(questions[i]) < len_seq:\n",
        "        # print(questions[i])\n",
        "        sorted_ques.append(questions[i])\n",
        "        sorted_ans.append(answers[i])"
      ],
      "metadata": {
        "id": "0hXMQWRNkW7j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
        "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
        "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
        "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
        "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
        "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
        "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
        "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
        "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
        "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
        "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
        "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
        "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
        "    return txt"
      ],
      "metadata": {
        "id": "cteUBavjlZgW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_ques = []\n",
        "clean_ans = []\n",
        "\n",
        "for line in sorted_ques:\n",
        "    clean_ques.append(clean_text(line))\n",
        "    \n",
        "for line in sorted_ans:\n",
        "    clean_ans.append(clean_text(line))\n",
        "\n",
        "for i in range(len(clean_ans)):\n",
        "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])"
      ],
      "metadata": {
        "id": "LpOHlKJclcI1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_ques[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWK723ZOl2Ur",
        "outputId": "fcec1587-2cb6-433e-86ef-91615d148f50"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cameron',\n",
              " 'why',\n",
              " 'there',\n",
              " 'sure have',\n",
              " 'hi',\n",
              " 'i was',\n",
              " 'well no',\n",
              " 'but',\n",
              " 'what crap',\n",
              " 'no']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(clean_ques))\n",
        "print(len(clean_ans))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkhC5rwilgqU",
        "outputId": "bba589f0-7a4e-4925-b1ff-63800d76f548"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31416\n",
            "31416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(answers, questions, line,sorted_ans, sorted_ques)"
      ],
      "metadata": {
        "id": "M4qJW1Bfy0bY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trimming\n",
        "clean_ans=clean_ans[:30000]\n",
        "clean_ques=clean_ques[:30000]"
      ],
      "metadata": {
        "id": "GDDcU6olus5h"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Count Occurences \n",
        "word2count = {}\n",
        "\n",
        "for line in clean_ques:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "            \n",
        "for line in clean_ans:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1"
      ],
      "metadata": {
        "id": "WUNQ5nuCluGr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(word2count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGciuokPmD37",
        "outputId": "b0bb12bc-9d2e-4223-c021-c0df7c6ca709"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(word, line)"
      ],
      "metadata": {
        "id": "c8Q51OlOy4EY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh = 5\n",
        "vocab = {}\n",
        "word_num = 0\n",
        "for word, count in word2count.items():\n",
        "    if count >= thresh:\n",
        "        vocab[word] = word_num\n",
        "        word_num += 1"
      ],
      "metadata": {
        "id": "IWqUBOM4mJmz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(word2count, word, count, thresh,word_num)      "
      ],
      "metadata": {
        "id": "iw8Ob9FAy79K"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvXIR30rmWcM",
        "outputId": "174ae580-16ee-487c-cff9-512680a27808"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict(list(vocab.items())[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEobxXDjm3qH",
        "outputId": "5168d7df-be05-4b86-c043-b39f0ab9c166"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cameron': 0,\n",
              " 'have': 4,\n",
              " 'hi': 5,\n",
              " 'i': 6,\n",
              " 'no': 9,\n",
              " 'sure': 3,\n",
              " 'there': 2,\n",
              " 'was': 7,\n",
              " 'well': 8,\n",
              " 'why': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(clean_ans)):\n",
        "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n",
        "\n",
        "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
        "x = len(vocab)\n",
        "\n",
        "for token in tokens:\n",
        "    vocab[token] = x\n",
        "    x += 1\n",
        "    \n",
        "vocab['cameron'] = vocab['<PAD>']\n",
        "vocab['<PAD>'] = 0"
      ],
      "metadata": {
        "id": "zWChbQAymQ80"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse Answers Dictionary \n",
        "inv_vocab = {w:v for v, w in vocab.items()}"
      ],
      "metadata": {
        "id": "UIc0e5mMnBvj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inp = []\n",
        "for line in clean_ques:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])\n",
        "        \n",
        "    encoder_inp.append(lst)"
      ],
      "metadata": {
        "id": "D6wwf9vbnMNb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inp = []\n",
        "for line in clean_ans:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])        \n",
        "    decoder_inp.append(lst)"
      ],
      "metadata": {
        "id": "4ZwgKED3nX4D"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(clean_ans, clean_ques, line, lst, word)"
      ],
      "metadata": {
        "id": "XMwywpGD0-Cf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding the inputs for LSTM Model"
      ],
      "metadata": {
        "id": "Eg1LZKaqn7BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "iAXcnim6nbKa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inp = pad_sequences(encoder_inp, len_seq, padding='post', truncating='post')\n",
        "decoder_inp = pad_sequences(decoder_inp, len_seq, padding='post', truncating='post')\n",
        "decoder_final_output = []"
      ],
      "metadata": {
        "id": "rKNiPPqjn-DD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_inp[0])\n",
        "print(encoder_inp[1])\n",
        "print(encoder_inp[3])\n",
        "print(encoder_inp[4])\n",
        "print(encoder_inp[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBiMwFltoDu7",
        "outputId": "8100c4cb-9f3a-4985-84b6-c101542f3c41"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3023    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[3 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[5 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[6 7 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_inp[1])\n",
        "print(decoder_inp[2])\n",
        "print(decoder_inp[3])\n",
        "print(decoder_inp[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUMTEswwqo5k",
        "outputId": "948ce10d-3786-491c-e273-22b1a83f5fb7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3026 3025  938   14 1042   18  227  125 2234   70   14 2235 3024]\n",
            "[3026  151 3024    0    0    0    0    0    0    0    0    0    0]\n",
            "[3026    6  125  125  125 1035   31   10    6  235   29   29 3024]\n",
            "[3026 1482  364  883  986   35  105   64 3024    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in decoder_inp:\n",
        "    decoder_final_output.append(i[1:]) \n",
        "decoder_final_output = pad_sequences(decoder_final_output, len_seq, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "ZgDiuii5qT9r"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_final_output[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_GeOXe9uXVp",
        "outputId": "aa50d14b-3ed7-447c-96ae-7a0d9259fe82"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3025,  938,   14, 1042,   18,  227,  125, 2234,   70,   14, 2235,\n",
              "       3024,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(decoder_final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_5U-miRu9hh",
        "outputId": "929101db-ab51-4c35-98e9-33b17d701692"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding\n",
        "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
        "print(decoder_final_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k3Z7tuouUSg",
        "outputId": "ccd2f9f5-0f2c-4f70-ea37-b32683cb3d48"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 13, 3027)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_final_output[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDRi65xzugiC",
        "outputId": "a99c01d7-82f1-4051-e45e-dafa97b9bbe8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 3027)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_final_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caRbyg14reej",
        "outputId": "c12b3870-b2f1-4bb4-cd4a-bc0b4cdaa651"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 13, 3027)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Encoding Model Using LSTM"
      ],
      "metadata": {
        "id": "QBwVdsKMrrIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input"
      ],
      "metadata": {
        "id": "D6LTV8sD12V-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define"
      ],
      "metadata": {
        "id": "ghdknlR3137a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inp = Input(shape=(len_seq, ))\n",
        "dec_inp = Input(shape=(len_seq, ))"
      ],
      "metadata": {
        "id": "THCfFRAOrtIc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example"
      ],
      "metadata": {
        "id": "N11CN6Dx15kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd4-5o-32K98",
        "outputId": "53bb4e67-0a4d-45d7-9e58-cacfe570f406"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 13) dtype=float32 (created by layer 'input_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_enc_inp = tf.random.uniform([13])\n",
        "sample_enc_inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCsS1oD9164y",
        "outputId": "aca2644a-9a9a-4d94-a465-08141b7efa8a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(13,), dtype=float32, numpy=\n",
              "array([0.7001265 , 0.4970715 , 0.6055653 , 0.7484348 , 0.00121987,\n",
              "       0.6239786 , 0.78449583, 0.6244222 , 0.6705291 , 0.8587234 ,\n",
              "       0.16885614, 0.07220101, 0.6561794 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding"
      ],
      "metadata": {
        "id": "o7djxeqG10oB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define"
      ],
      "metadata": {
        "id": "kkevJiFN2hM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(vocab)\n",
        "embed = Embedding(VOCAB_SIZE+1, output_dim=50, \n",
        "                  input_length=len_seq,\n",
        "                  trainable=True                  \n",
        "                  )\n"
      ],
      "metadata": {
        "id": "QS4FUI37rwei"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example"
      ],
      "metadata": {
        "id": "BnyRbqei2jLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_embed_output = embed(sample_enc_inp)\n",
        "print('Sample Input shape:',sample_enc_inp.shape)\n",
        "print('Embedding shape:',sample_embed_output.shape)\n",
        "print('Sample Embedding output:',sample_embed_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbOuJu4f2geI",
        "outputId": "b1b61694-32ca-4d85-dd49-c80087d4706f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Input shape: (13,)\n",
            "Embedding shape: (13, 50)\n",
            "Sample Embedding output: tf.Tensor(\n",
            "[[ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]\n",
            " [ 0.01936317 -0.01088672 -0.04592518  0.04225529 -0.02150883 -0.02451255\n",
            "   0.04323376  0.04236109 -0.02838469 -0.01695157  0.04597339 -0.00625571\n",
            "  -0.02547598  0.02164024 -0.03197128  0.01661642 -0.00154318 -0.02228051\n",
            "   0.03335586 -0.04345443 -0.01828034 -0.0427439  -0.03989242  0.0277716\n",
            "  -0.0080427   0.03956682 -0.00892466  0.04158759 -0.01139046 -0.04677073\n",
            "  -0.02946305 -0.03070389  0.00944073 -0.00595182  0.00897158 -0.00444914\n",
            "  -0.01971393  0.02457816 -0.00492668 -0.00213995  0.02259708  0.0439817\n",
            "   0.03988191 -0.03934822 -0.02032069 -0.03374827 -0.02982423  0.00772643\n",
            "  -0.03224834  0.00532309]], shape=(13, 50), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoder"
      ],
      "metadata": {
        "id": "r0n3NW4lz3ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define"
      ],
      "metadata": {
        "id": "tUmtbbXnz8X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_vocab_size, embedding_dim, enc_units, len_seq,**kwargs):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "        self.enc_units = enc_units\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.len_seq = len_seq\n",
        "        self.embedding_dim = embedding_dim\n",
        "        \n",
        "        self.embed = Embedding(self.input_vocab_size, output_dim=self.embedding_dim, \n",
        "                  input_length=self.len_seq,\n",
        "                  trainable=True                  \n",
        "                  )\n",
        "        self.enc_lstm = Bidirectional(LSTM(self.enc_units, return_state=True, dropout=0.05, return_sequences = True))\n",
        "\n",
        "    def call(self, enc_inp, state=None):\n",
        "        enc_embed = self.embed(enc_inp)\n",
        "        encoder_outputs, forward_h, forward_c, backward_h, backward_c = self.enc_lstm(enc_embed)\n",
        "        state_h = Concatenate()([forward_h, backward_h])\n",
        "        state_c = Concatenate()([forward_c, backward_c])\n",
        "\n",
        "        enc_states = [state_h, state_c]\n",
        "\n",
        "        return encoder_outputs, enc_states\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'input_vocab_size': self.input_vocab_size, \n",
        "            'embedding_dim': self.embedding_dim, \n",
        "            'enc_units': self.enc_units, \n",
        "            'len_seq': self.len_seq\n",
        "        })\n",
        "        return config\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "HK_DYBhIYRM7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(\n",
        "    input_vocab_size=VOCAB_SIZE+1, \n",
        "    embedding_dim=50, \n",
        "    enc_units=400,\n",
        "    len_seq=13\n",
        ")"
      ],
      "metadata": {
        "id": "IHT7kufR2H3P"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_outputs, enc_states = encoder(enc_inp)"
      ],
      "metadata": {
        "id": "Lq2piSl_2EIL"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# enc_embed = embed(enc_inp)\n",
        "# enc_lstm = Bidirectional(LSTM(400, return_state=True, dropout=0.05, return_sequences = True))\n",
        "\n",
        "# encoder_outputs, forward_h, forward_c, backward_h, backward_c = enc_lstm(enc_embed)\n",
        "\n",
        "# state_h = Concatenate()([forward_h, backward_h])\n",
        "# state_c = Concatenate()([forward_c, backward_c])\n",
        "\n",
        "# enc_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "RxdM2sWnry9K"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example"
      ],
      "metadata": {
        "id": "nBK24Kmiz9t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder = Encoder(\n",
        "    input_vocab_size=VOCAB_SIZE+1, \n",
        "    embedding_dim=50, \n",
        "    enc_units=400,\n",
        "    len_seq=13\n",
        ")"
      ],
      "metadata": {
        "id": "147JxsUlbLBe"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder_output, sample_states = sample_encoder(\n",
        "    tf.random.uniform((64,13))\n",
        ")\n",
        "sample_encoder_outputs = sample_encoder_output\n",
        "sample_state_h = sample_states[0]\n",
        "sample_state_c = sample_states[1]\n",
        "print('Encoder output shape:',sample_encoder_outputs.shape)\n",
        "print('State_h output shape:',sample_state_h.shape)\n",
        "print('State_c output shape:',sample_state_c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpOixYk5dCot",
        "outputId": "ea3ff47f-23a2-4ad0-a45b-7b6270bef09a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (64, 13, 800)\n",
            "State_h output shape: (64, 800)\n",
            "State_c output shape: (64, 800)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_encoder_output = enc_lstm(\n",
        "#     tf.random.uniform((1, 13, 50))\n",
        "# )\n",
        "# sample_encoder_outputs = sample_encoder_output[0]\n",
        "# sample_forward_h = sample_encoder_output[1]\n",
        "# sample_forward_c = sample_encoder_output[2]\n",
        "# sample_backward_h = sample_encoder_output[3]\n",
        "# sample_backward_c = sample_encoder_output[4]\n",
        "# print('Encoder output shape:',sample_encoder_outputs.shape)\n",
        "# print('Forward_h output shape:',sample_forward_h.shape)\n",
        "# print('Forward_c output shape:',sample_forward_c.shape)\n",
        "# print('Backward_h output shape:',sample_backward_h.shape)\n",
        "# print('Backward_c output shape:',sample_backward_c.shape)"
      ],
      "metadata": {
        "id": "WyA2NuORz_Zd"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_state_h = Concatenate()([sample_forward_h, sample_backward_h])\n",
        "# sample_state_c = Concatenate()([sample_forward_h, sample_backward_h])\n",
        "\n",
        "# print('State_h shape:',sample_state_h.shape)\n",
        "# print('State_c shape:',sample_state_c.shape)"
      ],
      "metadata": {
        "id": "8154hG2-6IsJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_enc_states = [sample_state_h, sample_state_c]\n",
        "# print('Encoder state shape:',len(sample_enc_states))\n",
        "# sample_enc_states"
      ],
      "metadata": {
        "id": "UDiM7z8r7L2A"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Attention Layer"
      ],
      "metadata": {
        "id": "7fbpD9sRjliJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define"
      ],
      "metadata": {
        "id": "pFSbdG2tjliK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        # units=400*2\n",
        "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "        self.attn_layer = AdditiveAttention(use_scale=True) \n",
        "\n",
        "    def call(self, query, value):\n",
        "        w1_query = self.W1(query)\n",
        "        w2_key = self.W2(value)\n",
        "        context_vector, attention_weights = self.attn_layer(\n",
        "            [w1_query, value, w2_key],\n",
        "            return_attention_scores = True\n",
        "        )\n",
        "\n",
        "        return context_vector, attention_weights\n"
      ],
      "metadata": {
        "id": "EyGa7ePqjliK"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example"
      ],
      "metadata": {
        "id": "aP6b8FK3jm-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_attn = AttentionLayer(units=800)"
      ],
      "metadata": {
        "id": "aKyaWVdfjpSK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output = tf.random.uniform((1,13,800))\n",
        "sample_encoder_outputs = tf.random.uniform((1,13,800))"
      ],
      "metadata": {
        "id": "3cIUHDWKj_-g"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_context_vector, sample_attention_weights = sample_attn(\n",
        "    query=sample_output,\n",
        "    value=sample_encoder_outputs\n",
        ")"
      ],
      "metadata": {
        "id": "h4Oab1KskMZY"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Context vector shape:', sample_context_vector.shape)\n",
        "print('Attention weight shape:', sample_attention_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5rf3n8wketZ",
        "outputId": "f6840709-fae3-4bc9-ee5a-7ed521a7ecfd"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context vector shape: (1, 13, 800)\n",
            "Attention weight shape: (1, 13, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_w1_query = W1(sample_output)\n",
        "# sample_w2_key = W2(sample_encoder_outputs)\n",
        "# sample_context_vector, sample_attention_weights = attn_layer(\n",
        "#     [sample_w1_query, sample_encoder_outputs, sample_w2_key],\n",
        "#     return_attention_scores = True\n",
        "# )\n",
        "\n",
        "# print('Context vector shape:', sample_context_vector.shape)\n",
        "# print('Attention weight shape:', sample_attention_weights.shape)\n",
        "# print('W1 query shape:', sample_w1_query.shape)"
      ],
      "metadata": {
        "id": "VV_SDX-d9hYi"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decoder"
      ],
      "metadata": {
        "id": "m-vGKRKVz5Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define"
      ],
      "metadata": {
        "id": "bEORjwYm0AO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_vocab_size, embedding_dim, dec_units, len_seq, **kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "        self.dec_units = dec_units\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.len_seq = len_seq\n",
        "\n",
        "        self.embed = Embedding(self.output_vocab_size, output_dim=embedding_dim, \n",
        "            input_length=self.len_seq,\n",
        "            trainable=True                  \n",
        "        )\n",
        "        # dec_units=400*2\n",
        "        self.dec_lstm = LSTM(dec_units, return_state=True, return_sequences=True, dropout=0.05)\n",
        "        self.attention = AttentionLayer(self.dec_units)\n",
        "\n",
        "        self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "        \n",
        "        self.fc = tf.keras.layers.Dense(self.output_vocab_size, activation='softmax')\n",
        "\n",
        "    def call(self, dec_inp, enc_output, state=None):\n",
        "        dec_embed = self.embed(dec_inp)\n",
        "        output, h, c = self.dec_lstm(dec_embed, initial_state=state)\n",
        "\n",
        "        context_vector, attention_weights = self.attention(\n",
        "            query=output, value=enc_output\n",
        "        )\n",
        "\n",
        "\n",
        "        decoder_concat_input = Concatenate(axis=-1)([context_vector, output])\n",
        "\n",
        "        attention_vector = self.Wc(decoder_concat_input)\n",
        "        logits = self.fc(attention_vector)\n",
        "        state = [h, c]\n",
        "        return logits, attention_weights, state\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'output_vocab_size':self.output_vocab_size, \n",
        "            'embedding_dim':self.embedding_dim, \n",
        "            'dec_units':self.dec_units, \n",
        "            'len_seq':self.len_seq\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "mpdfpNu7k4jh"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(\n",
        "    VOCAB_SIZE,\n",
        "    embedding_dim=50, \n",
        "    dec_units=400*2,\n",
        "    len_seq=13\n",
        ")"
      ],
      "metadata": {
        "id": "enDNbtIcntnc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits, attention_weights, state = decoder(\n",
        "    dec_inp=dec_inp,\n",
        "    enc_output=encoder_outputs, \n",
        "    state=enc_states\n",
        ")"
      ],
      "metadata": {
        "id": "xPAaq_yO234R"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example"
      ],
      "metadata": {
        "id": "uVMHQYSNxLG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_index = vocab['<SOS>']\n",
        "first_token = tf.constant([[start_index]] * sample_encoder_output.shape[0])\n",
        "first_token.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa8eMIpNqrA4",
        "outputId": "56c5d512-9a9e-4bd6-8f72-880a3c57bb40"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_output, sample_attention_weights, sample_state = decoder(\n",
        "    dec_inp=first_token,\n",
        "    enc_output=sample_encoder_output,\n",
        "    state=sample_states\n",
        ")"
      ],
      "metadata": {
        "id": "39F7wDQ7rLI8"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WdwafWqFlky",
        "outputId": "32edcf45-8670-451d-ae3c-1685025ad918"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 13, 800])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Output shape: (batch_size, t, output_vocab_size) {sample_output.shape}')\n",
        "print(f'State_h shape: (batch_size, dec_units) {sample_state[0].shape}')\n",
        "print(f'State_c shape: (batch_size, dec_units) {sample_state[1].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51xBZwwxuQ_3",
        "outputId": "d718e351-b678-46d3-c26d-525d25fa3b72"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (batch_size, t, output_vocab_size) (64, 1, 3027)\n",
            "State_h shape: (batch_size, dec_units) (64, 800)\n",
            "State_c shape: (batch_size, dec_units) (64, 800)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_token = tf.random.categorical(sample_output[:, 0, :], num_samples=1)\n",
        "first_word = [inv_vocab[x] for x in sampled_token.numpy().squeeze(axis=-1)]\n",
        "first_word[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GToOrIAKu3Im",
        "outputId": "66c30cf5-1f09-4f24-854b-4932db73bcf6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yourself', 'grady', 'hanging', 'goodness', 'women']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dec_inp = Input(shape=(13, ))\n",
        "# dec_embed = embed(dec_inp)\n",
        "# dec_lstm = LSTM(400*2, return_state=True, return_sequences=True, dropout=0.05)\n",
        "# output, _, _ = dec_lstm(dec_embed, initial_state=enc_states)"
      ],
      "metadata": {
        "id": "OcuOZTa5-aRF"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_concat_input = Concatenate(axis=-1)([context_vector, output])"
      ],
      "metadata": {
        "id": "GE0ZvKidCp8g"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wc = tf.keras.layers.Dense(400*2, activation=tf.math.tanh,\n",
        "#                                     use_bias=False)"
      ],
      "metadata": {
        "id": "aW6cIUeTmbrt"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# attention_vector = Wc(decoder_concat_input)"
      ],
      "metadata": {
        "id": "zudYv8uYv5pK"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_decoder_output = dec_lstm(\n",
        "#     tf.random.uniform((1, 13, 50)), initial_state=sample_enc_states\n",
        "# )\n",
        "# print('Decoder output shape:',sample_decoder_output[0].shape)"
      ],
      "metadata": {
        "id": "le-AqCAr0Dql"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_decoder_concat_input = Concatenate(axis=-1)([sample_context_vector, sample_output])\n",
        "\n",
        "# print(sample_decoder_concat_input.shape)"
      ],
      "metadata": {
        "id": "kbhxuX1zCH19"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_attention_vector = Wc(sample_decoder_concat_input)\n",
        "\n",
        "# print(sample_attention_vector.shape)"
      ],
      "metadata": {
        "id": "1_I95CpGw0wz"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dec_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "# final_output = dec_dense(attention_vector)"
      ],
      "metadata": {
        "id": "Y411ud-ud8GZ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_attention_vector = tf.random.uniform((1, 13,800))\n",
        "# sample_output = dec_dense(sample_attention_vector)\n",
        "\n",
        "# print('Output shape:', sample_output.shape)"
      ],
      "metadata": {
        "id": "77R9bjg2xJ62"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "CIJwvpSn9dfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([enc_inp, dec_inp], logits)"
      ],
      "metadata": {
        "id": "O5Aq2Y-cslLR"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')"
      ],
      "metadata": {
        "id": "IXVjTflWsn_B"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzj5QvOOsqBy",
        "outputId": "b605d793-0f20-4ad4-abc9-ea2c2287d882"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 13)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 13)]         0           []                               \n",
            "                                                                                                  \n",
            " encoder (Encoder)              ((None, 13, 800),    1594600     ['input_1[0][0]']                \n",
            "                                 [(None, 800),                                                    \n",
            "                                 (None, 800)])                                                    \n",
            "                                                                                                  \n",
            " decoder (Decoder)              ((None, 13, 3027),   7859977     ['input_2[0][0]',                \n",
            "                                 (None, 13, 13),                  'encoder[0][0]',                \n",
            "                                 [(None, 800),                    'encoder[0][1]',                \n",
            "                                 (None, 800)])                    'encoder[0][2]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,454,577\n",
            "Trainable params: 9,454,577\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "H = model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=50, batch_size=128)\n",
        "training_time = time.time() - start"
      ],
      "metadata": {
        "id": "gW-uQWWytQ_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568a6365-49e7-40c8-8b61-57db56f92eb7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 21s 58ms/step - loss: 3.3192 - acc: 0.4694\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 13s 56ms/step - loss: 2.8581 - acc: 0.5126\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 13s 56ms/step - loss: 2.6966 - acc: 0.5332\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 2.6112 - acc: 0.5416\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 2.5510 - acc: 0.5458\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 2.4982 - acc: 0.5491\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 2.4521 - acc: 0.5521\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 2.4089 - acc: 0.5545\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 2.3663 - acc: 0.5574\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 2.3251 - acc: 0.5600\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 14s 59ms/step - loss: 2.2815 - acc: 0.5628\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 2.2347 - acc: 0.5657\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 2.1836 - acc: 0.5691\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 2.1266 - acc: 0.5737\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 2.0597 - acc: 0.5791\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 1.9772 - acc: 0.5873\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 14s 57ms/step - loss: 1.8814 - acc: 0.5992\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 1.7704 - acc: 0.6159\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 1.6479 - acc: 0.6371\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 1.5249 - acc: 0.6600\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 1.4014 - acc: 0.6862\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 14s 59ms/step - loss: 1.2861 - acc: 0.7102\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 1.1853 - acc: 0.7329\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 1.0895 - acc: 0.7548\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 1.0079 - acc: 0.7729\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.9388 - acc: 0.7883\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.8769 - acc: 0.8019\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.8234 - acc: 0.8139\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.7765 - acc: 0.8240\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.7339 - acc: 0.8332\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.7009 - acc: 0.8407\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.6687 - acc: 0.8472\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.6376 - acc: 0.8538\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.6147 - acc: 0.8587\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.5931 - acc: 0.8631\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.5729 - acc: 0.8676\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.5556 - acc: 0.8716\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.5418 - acc: 0.8740\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.5279 - acc: 0.8766\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.5162 - acc: 0.8796\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.5045 - acc: 0.8816\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.4940 - acc: 0.8840\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 14s 59ms/step - loss: 0.4874 - acc: 0.8850\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.4782 - acc: 0.8872\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.4723 - acc: 0.8886\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.4683 - acc: 0.8892\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.4614 - acc: 0.8901\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.4573 - acc: 0.8914\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.4496 - acc: 0.8927\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 14s 58ms/step - loss: 0.4474 - acc: 0.8931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0QxynULnby6",
        "outputId": "ee85e33b-095e-4118-cd5d-e678c5f647ce"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "693.6489100456238"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(H.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Nx6zBIIOHmVZ",
        "outputId": "350a51fa-8de3-4bdb-d86f-8621845aebb3"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(H.history['acc'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WEIywuSLibo1",
        "outputId": "1891c451-2dbd-47f7-975c-539de9d72b7f"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9bnH8c9DyAJZgJCw75tssmgE1yquuGvba91arVvdqvbWtmpb29rbvbXVXmtre61aN9RWS62KiLiiSFhkXwKCYcsGCUkgCUme+8cc7IBRRsjkJJnv+/XKK3OWmXkOTM53zu+c8/uZuyMiIomrQ9gFiIhIuBQEIiIJTkEgIpLgFAQiIglOQSAikuAUBCIiCU5BIAnFzB4ys/+Jcd31ZnZyvGsSCZuCQEQkwSkIRNogM+sYdg3SfigIpNUJmmS+ZWaLzazazP7PzHqa2YtmVmlmr5hZt6j1zzGzZWZWbmavmdmoqGUTzWxB8LxpQNo+73WWmS0KnjvHzMbFWOOZZrbQzHaYWaGZ/XCf5ccGr1ceLL88mN/JzH5jZhvMrMLM3grmnWBmG5v4dzg5ePxDM3vGzB41sx3A5WY2yczeCd5ji5n9r5mlRD1/jJnNNLNtZlZkZneYWS8z22lm3aPWO8zMSswsOZZtl/ZHQSCt1ReAU4ARwNnAi8AdQC6Rz+1NAGY2AngCuCVY9gLwLzNLCXaKzwF/A7KBp4PXJXjuROBB4GtAd+BPwHQzS42hvmrgK0BX4EzgOjM7L3jdgUG9vw9qmgAsCp73a+Bw4Oigpm8DjTH+m5wLPBO852NAA/ANIAc4CjgJuD6oIRN4BXgJ6AMMA2a5+1bgNeCCqNf9MvCku++OsQ5pZxQE0lr93t2L3H0T8CYw190XunsN8CwwMVjvS8C/3X1msCP7NdCJyI72SCAZ+J2773b3Z4B5Ue9xDfAnd5/r7g3u/jBQGzzvU7n7a+6+xN0b3X0xkTA6Plh8MfCKuz8RvG+Zuy8ysw7AFcDN7r4peM857l4b47/JO+7+XPCeu9x9vru/6+717r6eSJDtqeEsYKu7/8bda9y90t3nBsseBi4FMLMk4CIiYSkJSkEgrVVR1ONdTUxnBI/7ABv2LHD3RqAQ6Bss2+R796y4IerxQOCbQdNKuZmVA/2D530qM5tsZrODJpUK4Foi38wJXmNtE0/LIdI01dSyWBTuU8MIM3vezLYGzUU/jaEGgH8Co81sMJGjrgp3f+8Aa5J2QEEgbd1mIjt0AMzMiOwENwFbgL7BvD0GRD0uBH7i7l2jfjq7+xMxvO/jwHSgv7t3Af4I7HmfQmBoE88pBWo+YVk10DlqO5KINCtF27er4PuBlcBwd88i0nQWXcOQpgoPjqqeInJU8GV0NJDwFATS1j0FnGlmJwUnO79JpHlnDvAOUA/cZGbJZvZ5YFLUc/8MXBt8uzczSw9OAmfG8L6ZwDZ3rzGzSUSag/Z4DDjZzC4ws45m1t3MJgRHKw8Cd5tZHzNLMrOjgnMSq4G04P2Tge8B+ztXkQnsAKrMbCRwXdSy54HeZnaLmaWaWaaZTY5a/ghwOXAOCoKEpyCQNs3dVxH5Zvt7It+4zwbOdvc6d68DPk9kh7eNyPmEf0Q9Nx+4GvhfYDtQEKwbi+uBu8ysEriTSCDted0PgTOIhNI2IieKxweLbwWWEDlXsQ34BdDB3SuC1/wLkaOZamCvq4iacCuRAKokEmrTomqoJNLsczawFVgDTIla/jaRk9QL3D26uUwSkGlgGpHEZGavAo+7+1/CrkXCpSAQSUBmdgQwk8g5jsqw65FwqWlIJMGY2cNE7jG4RSEgoCMCEZGEpyMCEZEE1+Y6rsrJyfFBgwaFXYaISJsyf/78Unff994UoA0GwaBBg8jPzw+7DBGRNsXMPvEyYTUNiYgkOAWBiEiCi2sQmNlUM1tlZgVmdlsTywea2SyL9Dv/mpn1i2c9IiLycXELgqDTrPuA04HRwEVmNnqf1X4NPOLu44C7gJ/Fqx4REWlaPI8IJgEF7r4u6PPlSSIDa0QbDbwaPJ7dxHIREYmzeAZBX/buP31jMC/a+0Q6BQM4H8iMHkJvDzO7xszyzSy/pKQkLsWKiCSqsE8W3wocb2YLiYystInI8Ht7cfcH3D3P3fNyc5u8DFZERA5QPO8j2ERkgJA9+gXzPuLumwmOCMwsA/iCu5fHsSYRkValsdGprqunqrae6tp6Kmvq2VnXQFVtPTvr6qmubaC6tp7qugZOGtmD8f27NnsN8QyCecDwYDi8TcCF7D14B2aWQ2Rwj0bgdiKDdoiItGkNjc72nXWUVdVRXFnD1orgZ8d/fpdW1VJVE9nBx6pHZmrbCgJ3rzezG4EZQBLwoLsvM7O7gHx3nw6cAPzMzBx4A7ghXvWIiBys+oZGiitr2bLXjn0XWyoiO/ayqjrKquvYvrOOpvrzzE5PoWdWGr2yUhnTJ4vMtGTSUzuSmdqR9NSOZKR1JCM1ifSUyHR6akfSU5LonNqRzslJdOhgH3/RZtDmeh/Ny8tzdTEhIs3F3amsraesqo5t1bWUVtVRWlVL8Y5aiitrKIr6XVpV+7EdfFpyB3plpdEjM43uGSlkp6fQPSOVnOBxbkYqvbt0okdWKmnJSeFsJGBm8909r6llba6vIRGRWFTW7OaD0mrWlVRTtKOG8l27Kd+5m/KddZHfu3azvbqObdV11DU0fuz5ZtA9PZWeWan0zErj0L5dyM1Mo3eXNHp1CX5npdGlUzJm8fmm3lIUBCLSZrk7WypqWF1UyZqiKtaVVrG2pJoPSqspqazda93kJKNLpxS6dk6mW+dk+nbtxNg+WXTPSKV7egrdM1I+epyTkUr3jBSSk8K+sLJlKAhEpNVzd4p21LK6qPKjnf7q4koKiqqorK3/aL3u6SkMzklnyiG5DM7JYEhuOkNy0undtRPpKUlt/pt7vCgIRKRVaWx0lm/ZQf76bawqqmJNsPPfUbP3Dn94zwzOP6wvw3tmMqJHBiN6ZtItPSXEytsuBYGIhG5z+S7eWlPKmwWlzCkopay6DoCunZMZ0SOTs8f3YUTPzOAng+4ZqSFX3L4oCESkxZVW1TJ33TbeXVfG22tLWVdSDUBuZirHj8jl2OE5HDW0O72y0tSc0wIUBCISd9uq63h3XdlHP6uLqgBIT0niiMHZXDxpAMcNz2VEzwzt+EOgIBCRZlff0Mj7G8t5fVUJr68uYfGmCtyhc0oSRwzK5vyJ/ThySDZj+3ZJmCtzWjMFgYg0i43bdzKnoIzXV5fw5poSdtTU08Fg4oBufOPkERwzLIdx/bTjb40UBCJyQMqqanlnXRlvF5QxZ20pG8p2AtAzK5WpY3tx/IgeHDsshy6dk0OuVPZHQSAiMXGPXNY5Y+lWXllRzPItOwDITO3I5CHZXHbUII4ZlqN2/jZIQSAin6ih0Zm/YTszlm1lxrKtbNy+iw4GeQOzufXUERw9LIdxfbvQUc09bZqCQET24u4sKizn2YWbeGHJFkqr6khJ6sAxw7rz9ROHcfKonrqOv51REIgIAB+W7eS5RZt4buEm1pVWk9KxAyeP6sHUsb2ZckgumWlq62+vFAQiCWxXXQP/en8zT+UXkr9hOwBHDsnma8cP4fRDe5OlnX9CUBCIJKAPy3by6NwNTJtXSMWu3QzNTedbpx3CeRP70rdrp7DLkxamIBBJEI2NzhtrSnjknQ3MXlVMBzOmjunFV44ayKTB2brSJ4EpCETauYZG51/vb+beV9ewrqSanIxUvj5lGBdPHkivLmlhlyetgIJApJ1qaHSeX7yZe2ZFAmBkr0zuuXACp4/tTUpHXe4p/6EgEGln9gTAvbPWsLakmkN6ZnL/JYdx2phecRv8XNo2BYFIO9HQ6Px7yRbunbWGguIqDumZyR8uOYypCgDZDwWBSBvXGBUAa4qrGN4jg/suPozTxyoAJDYKApE2qrHReXHpVu6ZtZrVRVUM65HB7y+ayJmH9lYAyGeiIBBpg+auK+POfy5jVVElQ3PTuTcIgCQFgBwABYFIG7KrroFfzljJQ3PW069bJ+65cAJnjeujAJCDoiAQaSPmb9jGrU8v5oPSai47aiDfOX0knVP0JywHT58ikVauZncDd89czZ/fXEefLp14/KrJHD0sJ+yypB1REIi0Yks2VnDLtIWsLanmokkD+O6Zo8hI1Z+tNC99okRaIXfn0Xc38OPnV5CdnsIjV0zicyNywy5L2ikFgUgrU1Vbz21/X8zzi7dwwiG53H3BBLLTU8IuS9oxBYFIK7Jiyw5ueGwB68uq+dZph3Dd8UN1T4DEnYJApJV4Kr+Q7z+3lKxOyTx+9ZEcOaR72CVJglAQiIRsd0Mj339uKU/OK+SYYd353ZcmkpupMYGl5SgIREK0s66e6x9bwGurSrhhylD++5RDdHOYtDgFgUhIyqpqueKheSzZVMFPzz+UiycPCLskSVAKApEQfFi2k688OJctFTX86ct5nDK6Z9glSQJTEIi0sCUbK/jqQ+9R3+g8fvVkDh+YHXZJkuAUBCIt6M01JVz7t/l07ZzCk1dMYliPjLBLEiGuA5ea2VQzW2VmBWZ2WxPLB5jZbDNbaGaLzeyMeNYjEqZZK4q44qF59M/uzD+uP1ohIK1G3ILAzJKA+4DTgdHARWY2ep/Vvgc85e4TgQuBP8SrHpEwzV5ZzHWPLmBU7yymfe0oemalhV2SyEfieUQwCShw93XuXgc8CZy7zzoOZAWPuwCb41iPSCheX13C1x6dz4heGfztisl06ZQcdkkie4lnEPQFCqOmNwbzov0QuNTMNgIvAF9v6oXM7Bozyzez/JKSknjUKhIXb6wu4epH8hmWm8GjV06mS2eFgLQ+cT1HEIOLgIfcvR9wBvA3M/tYTe7+gLvnuXtebq56YJS24a01pVz9SD5DczN47KrJdO2sjuOkdYpnEGwC+kdN9wvmRbsSeArA3d8B0gCNuCFt3pyCUq56ZB6Dc9J57KrJdFPvodKKxTMI5gHDzWywmaUQORk8fZ91PgROAjCzUUSCQG0/0qYtKiznyofzGZDdmceumqwupKXVi1sQuHs9cCMwA1hB5OqgZWZ2l5mdE6z2TeBqM3sfeAK43N09XjWJxFvhtp1c9fA8cjJTeOyqI+meoc7jpPWL6w1l7v4CkZPA0fPujHq8HDgmnjWItJQdNbu54qF51NU38uQ1R6oHUWkzdGexSDPY3dDIDY8t4IPSah65YhLDemSGXZJIzBQEIgfJ3bnzn0t5c00pv/ziOI4epusdpG0J+/JRkTbvgTfW8cR7hVx/wlAuyOu//yeItDIKApGD8OKSLfzsxZWcOa43t556SNjliBwQBYHIAVq8sZxbpi1i4oCu/Oa/xmuQeWmzFAQiB2B7dR3XPbqAnIxU/vyVPNKSk8IuSeSA6WSxyGfU2Oh846lFFFfW8PS1R5OjewWkjdMRgchndN/sAl5bVcKdZ41mQv+uYZcjctAUBCKfwVtrSrn7ldWcO6EPlx45MOxyRJqFgkAkRlsrarj5yYUMy83gp+cfiplODkv7oCAQicHuhkZueHwBu3Y3cP+lh5GeqtNr0n7o0ywSg5+9sJL5G7bz+4smqvsIaXd0RCCyHy8t3cKDb3/A5UcP4uzxfcIuR6TZKQhEPkX5zjq+++xSxvXrwh1njAq7HJG4UNOQyKf42QsrKd+1m79dOZmUjvreJO2TPtkin2DuujKm5Rdy1XGDGd0nK+xyROJGQSDShNr6Bm5/dgn9sztxy0kjwi5HJK7UNCTShPtfW8u6kmoevmISnVLUj5C0bzoiENlHQXEVf5i9lnPG9+H4EblhlyMSdwoCkSiNjc4dzy4hLbkD3z9rdNjliLQIBYFIlKfnF/LeB9u444xRGnxeEoaCQCRQWlXLT19YyaRB2RpyUhKKgkAk8D/PL2dnXT0//fxYjTYmCUVBIELknoHnFm3m2uOHqi8hSTgKAkl49Q2N/GD6Mvp27cT1JwwLuxyRFqcgkIT36LsbWLm1ku+fNUr3DEhCUhBIQiutquXumas5bngOp43pFXY5IqFQEEhC+9VLq9hZ18APzh6jEcckYSkIJGEtKixnWn4hVxw7mGE9MsIuRyQ0MQWBmf3DzM40MwWHtAuNjc4P/rmUHpmpfP1EnSCWxBbrjv0PwMXAGjP7uZkdEseaROLu6fmFvL+xgjvOGEVmWnLY5YiEKqYgcPdX3P0S4DBgPfCKmc0xs6+amf6KpE2p2LmbX7y0iiMGdePcCRp6UiTmph4z6w5cDlwFLATuIRIMM+NSmUic3D1zFeU76/jROWN1gliEGMcjMLNngUOAvwFnu/uWYNE0M8uPV3Eiza2guJK/vbuBSyYP1KhjIoFYB6a5191nN7XA3fOasR6RuPrlS6vonNKRb5yiUcdE9oi1aWi0mXXdM2Fm3czs+jjVJBIX8zds4+XlRVx7/BCy01PCLkek1Yg1CK529/I9E+6+Hbg6PiWJND935+cvriQ3M5Urjh0cdjkirUqsQZBkUWfVzCwJ0FcqaTNmrShm3vrt3HLycDqnaKhukWixBsFLRE4Mn2RmJwFPBPM+lZlNNbNVZlZgZrc1sfy3ZrYo+FltZuVNvY7IwWhodH7x0kqG5KRrwBmRJsT61eg7wNeA64LpmcBfPu0JwVHDfcApwEZgnplNd/fle9Zx929Erf91YGLspYvE5u8LNrKmuIr7LzmM5CTdHC+yr5iCwN0bgfuDn1hNAgrcfR2AmT0JnAss/4T1LwJ+8BleX2S/anY38NuZqxnfvytTx6p3UZGmxNrX0HAze8bMlpvZuj0/+3laX6AwanpjMK+p1x8IDAZe/YTl15hZvpnll5SUxFKyCAAPzVnPlooabj99pG4eE/kEsR4n/5XI0UA9MAV4BHi0Geu4EHjG3RuaWujuD7h7nrvn5ebmNuPbSntWvrOOP8wuYMohuRw5pHvY5Yi0WrEGQSd3nwWYu29w9x8CZ+7nOZuA6DNz/YJ5TbmQyAlokWZz/2trqayt59tTR4ZdikirFuvJ4tqgC+o1ZnYjkR36/jpwnwcMN7PBwfoXEunBdC9mNhLoBrwTc9Ui+7G5fBd/nbOe8yf2ZVRvdSUh8mliPSK4GegM3AQcDlwKXPZpT3D3euBGYAawAnjK3ZeZ2V1mdk7UqhcCT7q7f9biRT7J718twN35b3UlIbJf+z0iCC4D/ZK73wpUAV+N9cXd/QXghX3m3bnP9A9jfT2RWGwoq+bp/EIumTyAft06h12OSKu33yOC4ATusS1Qi0iz+N0ra+iYZNwwRSOPicQi1nMEC81sOvA0UL1nprv/Iy5ViRygNUWVPLdoE9ccN4QeWWlhlyPSJsQaBGlAGXBi1DwHFATSqtw9czXpKR259vihYZci0mbEemdxzOcFRMKydFMFLy7dys0nDaebupkWiVmsI5T9lcgRwF7c/Ypmr0jkAP3m5VV06ZTMlcepm2mRzyLWpqHnox6nAecDm5u/HJEDM3/DNmavKuE7U0eSlZYcdjkibUqsTUN/j542syeAt+JSkcgB+PWM1eRkpHLZ0QPDLkWkzTnQPnmHAz2asxCRA/V2QSnvrCvjhilDNeiMyAGI9RxBJXufI9hKZIwCkVC5O7+asYo+XdK4ePKAsMsRaZNibRrKjHchIgdi1opiFhWW8/PPH0pqx6SwyxFpk2Idj+B8M+sSNd3VzM6LX1ki+1ff0MjPgyEov3B4v7DLEWmzYj1H8AN3r9gz4e7laDQxCdm0/EIKiqv4zukjNQSlyEGI9a+nqfV0Vk5CU1Vbz29nrmbSoGxOHd0z7HJE2rRYgyDfzO42s6HBz93A/HgWJvJp/vT6Wkqr6rjjzFEaglLkIMUaBF8H6oBpwJNADXBDvIoS+TRbKnbx5zfXcc74Pkzo3zXsckTavFivGqoGbotzLSIx+c3Lq2lshG+ddkjYpYi0C7FeNTTTzLpGTXczsxnxK0ukacs37+DvCzZy+TGD6J+tQWdEmkOsTUM5wZVCALj7dnRnsbQwd+enL6ygS6dkbjhBg86INJdYg6DRzD66bdPMBtFEb6Qi8fT66hLeKijlphOH06WzOpYTaS6xXgL6XeAtM3sdMOA44Jq4VSWyj/qGRn76wgoGdu/MpUeqYzmR5hTTEYG7vwTkAauAJ4BvArviWJfIXp6ev5HVRVXcNnUkKR1185hIc4q107mrgJuBfsAi4EjgHfYeulIkLrZX1/GrGavIG9iNqWN7hV2OSLsT61erm4EjgA3uPgWYCJR/+lNEmscvZ6yiYtdufnzeWN08JhIHsQZBjbvXAJhZqruvBHQRt8Tdgg+388R7H/LVowcxqndW2OWItEuxnizeGNxH8Bww08y2AxviV5ZI5ATxd59dSq+sNG45ZUTY5Yi0W7HeWXx+8PCHZjYb6AK8FLeqRIBH3tnAii07uP+Sw8hIVR+HIvHymf+63P31eBQiEq1oRw13z1zN8SNydYJYJM50HZ60Snc9v5zdDY3cde4YnSAWiTMFgbQ6b6wu4d+Lt3DDlGEM7J4edjki7Z6CQFqVmt0N3PnPpQzOSedrxw8JuxyRhKAzcNKq/PH1tawv28mjV07WYPQiLURHBNJqLPhwO//7agHnjO/DscNzwi5HJGEoCKRV2F5dx42PLaB31zR+fO7YsMsRSShqGpLQNTY6//3UIkqr6njmuqPUxbRIC9MRgYTuj2+sZfaqEr5/1ijG9dMYxCItTUEgoXp3XRm/nrGKs8f30TgDIiFREEhoSipruemJhQzqns7PPn+obhwTCYnOEUgoGhqdW6YtpGLXbh65cpL6EhIJUVyPCMxsqpmtMrMCM7vtE9a5wMyWm9kyM3s8nvVI63HvrDW8XVDGj88by8he6l5aJExx+xpmZknAfcApwEZgnplNd/flUesMB24HjnH37WbWI171SOvx17c/4J5Za/jCYf24IK9/2OWIJLx4Ho9PAgrcfR2AmT0JnAssj1rnauA+d98O4O7FcaxHQubu/Hbmau59tYCpY3rxk/N1v4BIaxDPpqG+QGHU9MZgXrQRwAgze9vM3jWzqU29kJldY2b5ZpZfUlISp3Ilnhoane89t5R7Xy3gwiP6c98lh5GWrC4kRFqDsM/QdQSGAycA/YA3zOxQd99rPGR3fwB4ACAvL89bukg5OHX1jXzjqUX8e/EWrjthKN8+7RBdISTSisQzCDYB0Q3A/YJ50TYCc919N/CBma0mEgzz4liXtKDq2nqufXQ+b64p5btnjOLqz6lHUZHWJp5NQ/OA4WY22MxSgAuB6fus8xyRowHMLIdIU9G6ONYkLai4soZL/jKXOWvL+NUXxykERFqpuB0RuHu9md0IzACSgAfdfZmZ3QXku/v0YNmpZrYcaAC+5e5l8apJWs7slcXc+vT7VNfVc/8lh3HqGA03KdJamXvbanLPy8vz/Pz8sMuQT1Bb38DPX1zJX99ez8hemfz+ookM75kZdlkiCc/M5rt7XlPLwj5ZLO1IQXElX39iESu27ODyowdx2+kjdWWQSBugIJCD5u48Oa+QH/1rGZ1TOvJ/l+Vx0qieYZclIjFSEMhBWbyxnJ+/uJI5a8s4dlgOd18wnh5ZaWGXJSKfgYJADsj60mp+/fIqnl+8hez0FH50zhi+fORAOnTQ/QEibY2CQD6T0qpa7p21hsfnfkhyUgduOnEYV39uCJlpGlVMpK1SEMh+NTY6Cwu388KSrTz53ofU1Ddy4RH9ufmk4WoGEmkHFATSpN0Njcxdt42Xlm1hxrIiSiprSU4yTh3Ti2+eMoIhuRlhlygizURBIB/ZUrGLtwvKeLuglFdXFlOxazedkpOYMjKX08b0YsrIHmSpCUik3VEQJLDynXW8u67so53/utJqALLTUzhxZA+mju3F54bn0ilF9wKItGcKggSxrbqOpZsqWLq5gmWbdrB0cwUbynYC0DkliUmDs7l48gCOHprDyF6ZuvpHJIEoCNqpoh01vLWmlLcLSpn7wTY2le/6aFn/7E6M7dOFC/L6M2lwNuP7dSWlY1xHLRWRVkxB0E5U7NzN/A+38eaaUt5aU8qa4iog0sxz1JDuXHb0QMb26cKYPl3o0lnt/CLyHwqCNii6mWfppgqWbKqgcFvkG39qxw5MGpzNFw/vxzHDchjdO0vNPCLyqRQErZi7U7SjlmWbK1i6aQfLNlewbPOOvZp5BmR3Zlzfrlw0aQAT+nXlsIHd1NGbiHwmCoJWwt3ZuH1X1Df9yI6/tKoOADMYnJPOYQO78ZWjBnJoXzXziEjzUBCEpHhHDfM3bGdhYXlk57+pgh019QB07GAM65HBCYf0YGyfLMb07cKo3llkpOq/S0San/YsLaCh0VmxZQfzN2z/6GdP805KUgdG9c7krPF9GNunC2P7ZjGiZ6aad0SkxSgI4qR4Rw2vry7h9dUlvFVQSvnO3QD0ykrj8IHd+Ooxgzh8YDdG98kitaN2+iISHgVBM6nYtZtFheXMWVvK66tKWLm1EoDczFROHtWT44bncMSgbPp07RRypSIie1MQHAB3Z33Zzo+aeRZs2M7q4krcITnJyBuYzW2nj+T4EbmM7JWJmS7fFJHWS0HwGc0pKOXO6csoCG7YykrryGEDu3HWuN4cPrAb4/t3JV0ndUWkDdEeK0YllbX85N/LeW7RZgZkd+Yn549l0qBshuZm6IYtEWnTFAT70dDoPP7eh/zypZXU7G7gphOHcf2UYbqqR0TaDQXBp1i6qYLvPreU9wvLOXpod3583liGakAWEWlnFASfYE1RJZ+/fw5ZaR2558IJnDO+j076iki7pCBoQkOj861nFpOeksQLNx9Hj0yNyysi7Zc6oW/CQ3PWs6iwnB+cPUYhICLtnoJgHx+W7eTXM1Zx4sgenDuhT9jliIjEnYIgirtz2z8Wk9TB+J/zxuqcgIgkBAVBlGnzCpmztozbzxipriBEJGEoCAJbK2r4yb9XMHlwNhcdMSDsckREWoyCgEiT0PeeW0JdQyO/+MI43SksIglFQQD8a/EWXllRzDdPHcGgnPSwyxERaVEJHwTlO+v44fRljO/XhSuOGRx2OSIiLS7hbyh7fsF9dLUAAAfmSURBVPEWtlXX8dBXj6BjUsLnoogkoITf8728vIhB3TtzaN8uYZciIhKKhA6CHTW7eWdtKaeO6aV7BkQkYcU1CMxsqpmtMrMCM7utieWXm1mJmS0Kfq6KZz37mr2ymN0Nzqmje7bk24qItCpxO0dgZknAfcApwEZgnplNd/fl+6w6zd1vjFcdn+bl5UXkZKQycUC3MN5eRKRViOcRwSSgwN3XuXsd8CRwbhzf7zOprW/gtZXFnDK6B0m6b0BEElg8g6AvUBg1vTGYt68vmNliM3vGzPrHsZ69zCkoo7qugVNH92qptxQRaZXCPln8L2CQu48DZgIPN7WSmV1jZvlmll9SUtIsb/zy8q2kpyRx9LDuzfJ6IiJtVTyDYBMQ/Q2/XzDvI+5e5u61weRfgMObeiF3f8Dd89w9Lzc396ALa2h0Zi4v4oSRPUjtqLGHRSSxxTMI5gHDzWywmaUAFwLTo1cws95Rk+cAK+JYz0cWfrid0qo6XS0kIkIcrxpy93ozuxGYASQBD7r7MjO7C8h39+nATWZ2DlAPbAMuj1c90V5eXkRykjFlZI+WeDsRkVYtrl1MuPsLwAv7zLsz6vHtwO3xrKGJmpixbCtHDc0hKy25Jd9aRKRVCvtkcYtbXVTFhrKdahYSEQkkXBC8vGwrgIJARCSQeEGwvIiJA7rSIyst7FJERFqFhAqCTeW7WLKpQjeRiYhESaggmBk0C502Rs1CIiJ7JFQQvLy8iGE9MhiSmxF2KSIirUbCBMH26jrmfrBNJ4lFRPaRMEHw6spiGhqdU8fo/ICISLSECYKsTsmcMron4zQkpYjIXhJm8PpTRvfkFDULiYh8TMIcEYiISNMUBCIiCU5BICKS4BQEIiIJTkEgIpLgFAQiIglOQSAikuAUBCIiCc7cPewaPhMzKwE2HODTc4DSZiynrUjU7YbE3XZtd2KJZbsHuntuUwvaXBAcDDPLd/e8sOtoaYm63ZC4267tTiwHu91qGhIRSXAKAhGRBJdoQfBA2AWEJFG3GxJ327XdieWgtjuhzhGIiMjHJdoRgYiI7ENBICKS4BImCMxsqpmtMrMCM7st7HrixcweNLNiM1saNS/bzGaa2Zrgd7cwa4wHM+tvZrPNbLmZLTOzm4P57XrbzSzNzN4zs/eD7f5RMH+wmc0NPu/TzCwl7FrjwcySzGyhmT0fTLf77Taz9Wa2xMwWmVl+MO+gPucJEQRmlgTcB5wOjAYuMrPR4VYVNw8BU/eZdxswy92HA7OC6famHvimu48GjgRuCP6P2/u21wInuvt4YAIw1cyOBH4B/NbdhwHbgStDrDGebgZWRE0nynZPcfcJUfcOHNTnPCGCAJgEFLj7OnevA54Ezg25prhw9zeAbfvMPhd4OHj8MHBeixbVAtx9i7svCB5XEtk59KWdb7tHVAWTycGPAycCzwTz2912A5hZP+BM4C/BtJEA2/0JDupznihB0BcojJreGMxLFD3dfUvweCvQrgdvNrNBwERgLgmw7UHzyCKgGJgJrAXK3b0+WKW9ft5/B3wbaAymu5MY2+3Ay2Y238yuCeYd1Oc8YQavlwh3dzNrt9cMm1kG8HfgFnffEfmSGNFet93dG4AJZtYVeBYYGXJJcWdmZwHF7j7fzE4Iu54Wdqy7bzKzHsBMM1sZvfBAPueJckSwCegfNd0vmJcoisysN0DwuzjkeuLCzJKJhMBj7v6PYHZCbDuAu5cDs4GjgK5mtueLXnv8vB8DnGNm64k09Z4I3EP7327cfVPwu5hI8E/iID/niRIE84DhwRUFKcCFwPSQa2pJ04HLgseXAf8MsZa4CNqH/w9Y4e53Ry1q19tuZrnBkQBm1gk4hcj5kdnAF4PV2t12u/vt7t7P3QcR+Xt+1d0voZ1vt5mlm1nmnsfAqcBSDvJznjB3FpvZGUTaFJOAB939JyGXFBdm9gRwApFuaYuAHwDPAU8BA4h04X2Bu+97QrlNM7NjgTeBJfynzfgOIucJ2u22m9k4IicHk4h8sXvK3e8ysyFEvilnAwuBS929NrxK4ydoGrrV3c9q79sdbN+zwWRH4HF3/4mZdecgPucJEwQiItK0RGkaEhGRT6AgEBFJcAoCEZEEpyAQEUlwCgIRkQSnIBBpQWZ2wp6eMkVaCwWBiEiCUxCINMHMLg36+V9kZn8KOnarMrPfBv3+zzKz3GDdCWb2rpktNrNn9/QFb2bDzOyVYKyABWY2NHj5DDN7xsxWmtljFt0hkkgIFAQi+zCzUcCXgGPcfQLQAFwCpAP57j4GeJ3IXdsAjwDfcfdxRO5s3jP/MeC+YKyAo4E9vUNOBG4hMjbGECL95oiERr2PinzcScDhwLzgy3onIp14NQLTgnUeBf5hZl2Aru7+ejD/YeDpoD+Yvu7+LIC71wAEr/eeu28MphcBg4C34r9ZIk1TEIh8nAEPu/vte800+/4+6x1o/yzRfd80oL9DCZmahkQ+bhbwxaC/9z3jwQ4k8veyp2fLi4G33L0C2G5mxwXzvwy8HoySttHMzgteI9XMOrfoVojESN9ERPbh7svN7HtERoHqAOwGbgCqgUnBsmIi5xEg0u3vH4Md/Trgq8H8LwN/MrO7gtf4rxbcDJGYqfdRkRiZWZW7Z4Rdh0hzU9OQiEiC0xGBiEiC0xGBiEiCUxCIiCQ4BYGISIJTEIiIJDgFgYhIgvt/+cIg/s1Evv4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(H.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0unV26H3iNHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "1Zshu7us3CX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define"
      ],
      "metadata": {
        "id": "kqH_q8ZmoXj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_model = tf.keras.models.Model(enc_inp, [encoder_outputs, enc_states])\n",
        "\n"
      ],
      "metadata": {
        "id": "_qL1zZ0CPWXm"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmBWVPiDjhJx",
        "outputId": "9a0228ac-4455-4d6e-a356-154b06faa509"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 13)]              0         \n",
            "                                                                 \n",
            " encoder (Encoder)           ((None, 13, 800),         1594600   \n",
            "                              [(None, 800),                      \n",
            "                              (None, 800)])                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,594,600\n",
            "Trainable params: 1,594,600\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WigVZBcP8ILu",
        "outputId": "46a68449-e308-4a5a-cc95-9d0f931d0bec"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 13, 800])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_state_input_h = tf.keras.layers.Input(shape=( 400 * 2,))\n",
        "decoder_state_input_c = tf.keras.layers.Input(shape=( 400 * 2,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_enc_output_inputs = tf.keras.layers.Input(shape=( len_seq, 400 * 2,))\n",
        "\n",
        "decoder_outputs, attention_weights, decoder_states = decoder(\n",
        "    dec_inp=dec_inp,\n",
        "    enc_output=decoder_enc_output_inputs, \n",
        "    state=decoder_states_inputs\n",
        ")\n",
        "\n",
        "\n",
        "#decoder_output = dec_dense(decoder_outputs)\n",
        "\n",
        "dec_model = tf.keras.models.Model([dec_inp, decoder_enc_output_inputs] + decoder_states_inputs,\n",
        "                                      [decoder_outputs, attention_weights]+ decoder_states)"
      ],
      "metadata": {
        "id": "ipS8gDgV6NPD"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec_model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')"
      ],
      "metadata": {
        "id": "K5_hYhFAwtvo"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ett9t1BQjd03",
        "outputId": "5428aad3-2643-417b-dbef-336e6dd2a298"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 13)]         0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 13, 800)]    0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 800)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 800)]        0           []                               \n",
            "                                                                                                  \n",
            " decoder (Decoder)              ((None, 13, 3027),   7859977     ['input_2[0][0]',                \n",
            "                                 (None, 13, 13),                  'input_5[0][0]',                \n",
            "                                 [(None, 800),                    'input_3[0][0]',                \n",
            "                                 (None, 800)])                    'input_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,859,977\n",
            "Trainable params: 7,859,977\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_model.save('decoder_model.h5')\n",
        "enc_model.save('encoder_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNr501o-tU5U",
        "outputId": "66a70191-bbf6-4407-c75b-03efaccf4fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inference"
      ],
      "metadata": {
        "id": "CKhzFcIPoarK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "print(\"##########################################\")\n",
        "print(\"#       start chatting ver. 1.0          #\")\n",
        "print(\"##########################################\")\n",
        "\n",
        "\n",
        "prepro1 = \"\"\n",
        "while prepro1 != 'q':\n",
        "    \n",
        "    prepro1 = input(\"you : \")\n",
        "    try:\n",
        "        prepro1 = clean_text(prepro1)\n",
        "        prepro = [prepro1]\n",
        "        \n",
        "        txt = []\n",
        "        for x in prepro:\n",
        "            lst = []\n",
        "            for y in x.split():\n",
        "                try:\n",
        "                    lst.append(vocab[y])\n",
        "                except:\n",
        "                    lst.append(vocab['<OUT>'])\n",
        "            txt.append(lst)\n",
        "        txt = pad_sequences(txt, 13, padding='post')\n",
        "\n",
        "\n",
        "        ###\n",
        "        enc_op, stat = enc_model.predict( txt )\n",
        "\n",
        "        # empty_target_seq = np.zeros( ( 1 , 1) )\n",
        "        # empty_target_seq[0, 0] = vocab['<SOS>']\n",
        "\n",
        "        start_index = vocab['<SOS>']\n",
        "        empty_target_seq = tf.constant([[start_index]])\n",
        "        stop_condition = False\n",
        "        decoded_translation = ''\n",
        "\n",
        "\n",
        "        while not stop_condition :\n",
        "\n",
        "            dec_outputs , attention_weights, decoder_states_h, decoder_states_c = dec_model.predict([ empty_target_seq, enc_op ] + stat )\n",
        "\n",
        "            ###\n",
        "            ###########################\n",
        "            # w1_query_op = W1(dec_outputs)\n",
        "            # w2_key_op = W2(enc_op)\n",
        "\n",
        "            # context_vector_op, attn_weight_op = attn_layer(\n",
        "            #     [w1_query_op, enc_op, w2_key_op],\n",
        "            #     return_attention_scores = True\n",
        "            # )\n",
        "            # decoder_concat_input = Concatenate(axis=-1)([context_vector_op, dec_outputs])\n",
        "            # decoder_concat_input = Wc(decoder_concat_input)\n",
        "            # decoder_concat_input = dec_dense(decoder_concat_input)\n",
        "            ###########################\n",
        "\n",
        "            sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "\n",
        "            sampled_word = inv_vocab[sampled_word_index] + ' '\n",
        "\n",
        "            if sampled_word != '<EOS> ':\n",
        "                decoded_translation += sampled_word           \n",
        "\n",
        "\n",
        "            if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
        "                stop_condition = True\n",
        "\n",
        "            # empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "            empty_target_seq = tf.constant([[sampled_word_index]])\n",
        "            stat = [decoder_states_h, decoder_states_c]\n",
        "\n",
        "        print(\"chatbot attention : \", decoded_translation )\n",
        "        print(\"==============================================\")\n",
        "\n",
        "    except:\n",
        "        print(\"sorry didn't got you , please type again :( \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub8wnTuHPO0I",
        "outputId": "933b8c1e-df8c-461d-e7d5-302d01c11160"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################\n",
            "#       start chatting ver. 1.0          #\n",
            "##########################################\n",
            "you : Hi\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 13), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "chatbot attention :  hi \n",
            "==============================================\n",
            "you : Hello\n",
            "chatbot attention :  <OUT> \n",
            "==============================================\n",
            "you : Who are you\n",
            "chatbot attention :  i am your son \n",
            "==============================================\n",
            "you : How could you be my son\n",
            "chatbot attention :  <OUT> no other \n",
            "==============================================\n",
            "you : I have a daughter\n",
            "chatbot attention :  you want a man you got a <OUT> you have a \n",
            "==============================================\n",
            "you : I love you son\n",
            "chatbot attention :  yeah am you really bad \n",
            "==============================================\n",
            "you : I love you\n",
            "chatbot attention :  i love you walter did anyone ever call you anything other \n",
            "==============================================\n",
            "you : Do you have a crush\n",
            "chatbot attention :  no \n",
            "==============================================\n",
            "you : I have a crush\n",
            "chatbot attention :  the <OUT> came to your house he is got a bit \n",
            "==============================================\n",
            "you : I have a crush that is you\n",
            "chatbot attention :  you have a <OUT> you didnt have a hard choice your \n",
            "==============================================\n",
            "you : Do you want to sleep\n",
            "chatbot attention :  no \n",
            "==============================================\n",
            "you : Good night\n",
            "chatbot attention :  goodbye \n",
            "==============================================\n",
            "you : Good morning\n",
            "chatbot attention :  i thought i would stay the night \n",
            "==============================================\n",
            "you : Good bye\n",
            "chatbot attention :  i will see you there \n",
            "==============================================\n",
            "you : Bye\n",
            "chatbot attention :  monica \n",
            "==============================================\n",
            "you : Who is monica\n",
            "chatbot attention :  <OUT> \n",
            "==============================================\n",
            "you : Yes\n",
            "chatbot attention :  i was thinking that <OUT> know while i was up there \n",
            "==============================================\n",
            "you : q\n",
            "chatbot attention :  i was calling yesterday \n",
            "==============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.keras.utils.custom_object_scope({'Decoder': Decoder}):\n",
        "    new_dec = tf.keras.models.load_model('decoder_model.h5')"
      ],
      "metadata": {
        "id": "0-tJMHm5_t3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.keras.utils.custom_object_scope({'Encoder': Encoder}):\n",
        "    new_enc = tf.keras.models.load_model('encoder_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PBOKibQ-DM4",
        "outputId": "ff9c03e1-69ee-41c2-c36d-6f92bf5a87e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "print(\"##########################################\")\n",
        "print(\"#       start chatting ver. 1.0          #\")\n",
        "print(\"##########################################\")\n",
        "\n",
        "\n",
        "prepro1 = \"\"\n",
        "while prepro1 != 'q':\n",
        "    \n",
        "    prepro1 = input(\"you : \")\n",
        "    try:\n",
        "        prepro1 = clean_text(prepro1)\n",
        "        prepro = [prepro1]\n",
        "        \n",
        "        txt = []\n",
        "        for x in prepro:\n",
        "            lst = []\n",
        "            for y in x.split():\n",
        "                try:\n",
        "                    lst.append(vocab[y])\n",
        "                except:\n",
        "                    lst.append(vocab['<OUT>'])\n",
        "            txt.append(lst)\n",
        "        txt = pad_sequences(txt, 13, padding='post')\n",
        "\n",
        "\n",
        "        ###\n",
        "        enc_op, stat = new_enc.predict( txt )\n",
        "\n",
        "        # empty_target_seq = np.zeros( ( 1 , 1) )\n",
        "        # empty_target_seq[0, 0] = vocab['<SOS>']\n",
        "\n",
        "        start_index = vocab['<SOS>']\n",
        "        empty_target_seq = tf.constant([[start_index]])\n",
        "        stop_condition = False\n",
        "        decoded_translation = ''\n",
        "\n",
        "\n",
        "        while not stop_condition :\n",
        "\n",
        "            dec_outputs , attention_weights, decoder_states_h, decoder_states_c = new_dec.predict([ empty_target_seq, enc_op ] + stat )\n",
        "\n",
        "            ###\n",
        "            ###########################\n",
        "            # w1_query_op = W1(dec_outputs)\n",
        "            # w2_key_op = W2(enc_op)\n",
        "\n",
        "            # context_vector_op, attn_weight_op = attn_layer(\n",
        "            #     [w1_query_op, enc_op, w2_key_op],\n",
        "            #     return_attention_scores = True\n",
        "            # )\n",
        "            # decoder_concat_input = Concatenate(axis=-1)([context_vector_op, dec_outputs])\n",
        "            # decoder_concat_input = Wc(decoder_concat_input)\n",
        "            # decoder_concat_input = dec_dense(decoder_concat_input)\n",
        "            ###########################\n",
        "\n",
        "            sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "\n",
        "            sampled_word = inv_vocab[sampled_word_index] + ' '\n",
        "\n",
        "            if sampled_word != '<EOS> ':\n",
        "                decoded_translation += sampled_word           \n",
        "\n",
        "\n",
        "            if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
        "                stop_condition = True\n",
        "\n",
        "            # empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "            empty_target_seq = tf.constant([[sampled_word_index]])\n",
        "            stat = [decoder_states_h, decoder_states_c]\n",
        "\n",
        "        print(\"chatbot attention : \", decoded_translation )\n",
        "        print(\"==============================================\")\n",
        "\n",
        "    except:\n",
        "        print(\"sorry didn't got you , please type again :( \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKMxnOnDBfAp",
        "outputId": "83b488fc-3de6-4968-e095-aa66a9f808fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################\n",
            "#       start chatting ver. 1.0          #\n",
            "##########################################\n",
            "you : hello\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 13), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 13), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chatbot attention :  hi its me just who you wanted to talk to right \n",
            "==============================================\n",
            "you : how can you know\n",
            "chatbot attention :  no \n",
            "==============================================\n",
            "you : Do you know\n",
            "chatbot attention :  no \n",
            "==============================================\n",
            "you : I love you\n",
            "chatbot attention :  i love you walter did anyone ever call you anything other \n",
            "==============================================\n",
            "you : I love you too\n",
            "chatbot attention :  i love you dad i feel well i have to but \n",
            "==============================================\n",
            "you : I want to kiss you\n",
            "chatbot attention :  edward that is okay \n",
            "==============================================\n",
            "you : hello\n",
            "chatbot attention :  hi its me just who you wanted to talk to right \n",
            "==============================================\n",
            "you : what's your name?\n",
            "chatbot attention :  the baby the hell theres a football program \n",
            "==============================================\n",
            "you : Your name\n",
            "chatbot attention :  thomas kent i would like to do a speech by a \n",
            "==============================================\n",
            "you : Remember\n",
            "chatbot attention :  no that was years ago i have lived years since then \n",
            "==============================================\n",
            "you : How old are you\n",
            "chatbot attention :  17 \n",
            "==============================================\n",
            "you : Bye never want to see you\n",
            "chatbot attention :  i am <OUT> \n",
            "==============================================\n",
            "you : Bye forever\n",
            "chatbot attention :  and thanks \n",
            "==============================================\n",
            "you : Bye\n",
            "chatbot attention :  bye \n",
            "==============================================\n",
            "you : q\n",
            "chatbot attention :  i am <OUT> \n",
            "==============================================\n"
          ]
        }
      ]
    }
  ]
}